{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generating files with label for leaderboard test\n",
    "\n",
    "In this kit, we will show how to use the trained model to generate labels and save the labels for uploading. We recommand you to read the 'LeaderboardDataGuide' to get familar with the test data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from util.preproc import balance_set,plot_confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "from braindecode.util import np_to_var, var_to_np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from braindecode.util import set_random_seeds\n",
    "import util.shallow_net\n",
    "from util.utilfunc import get_balanced_batches\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print('gpu condition: ', cuda)\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "\n",
    "SEED=42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "rng = RandomState(SEED)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "gpu condition:  True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**These Objects are the same as in sleep and motor imagery kits.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class TestObject(object):\n",
    "    def __init__(self, X):\n",
    "        mean=np.mean(X,axis=1,keepdims=True)\n",
    "        std=np.std(X,axis=1,keepdims=True)\n",
    "        X=(X-mean)/(std)\n",
    "        #we scale it to 1000 as a better training scale of the shallow CNN\n",
    "        #according to the orignal work of the paper\n",
    "        self.X = X.astype(np.float32)*1e3\n",
    "class SleepObject(object):\n",
    "    def __init__(self, X):\n",
    "        mean=np.mean(X,axis=2,keepdims=True)\n",
    "        #here normalise across the window, when channel size is large enough\n",
    "        std=np.std(X,axis=2,keepdims=True)\n",
    "        X=(X-mean)/(std)\n",
    "        #we scale it to 1000 as a better training scale of the shallow CNN\n",
    "        #according to the orignal work of the paper\n",
    "        self.X = X.astype(np.float32)*1e3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sleep_label=None\n",
    "MI_s1=None\n",
    "MI_s2=None\n",
    "MI_s3=None\n",
    "MI_s4=None\n",
    "MI_s5=None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Loading test data has been explained in the DataGuide. Replace the 'savebase' part with your folder. After loading the test data, model trained with the training set can be loaded to do the prediction. 13094 trials for leaderboard sleep test data.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "savebase = '/home/moja/mne_data/MNE-beetlsleepleaderboard-data/testing/'\n",
    "\n",
    "X_test = []\n",
    "for subj in range(6, 18):\n",
    "    for session in range(1, 3):\n",
    "        with open(savebase + \"leaderboard_s{}r{}X.npy\".format(subj, session), 'rb') as f:\n",
    "            X_test.append(pickle.load(f))\n",
    "X_test = np.concatenate(X_test)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = SleepObject(X_test)\n",
    "print(test_set.X[1,:,:20])\n",
    "\n",
    "\n",
    "savebase0='D:\\\\sleep'\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, 6, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "checkpoint = torch.load(savebase0+'\\\\cnn_model_sleep.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "#shuffle=False to make sure it's in the orignial order\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "sleep_label = predicted_labels\n",
    "predicted_labels[:100]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './LeaderboardSleep/testing/leaderboard_s6r1X.npy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7cbc61f5137e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavebase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"leaderboard_s{}r{}X.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './LeaderboardSleep/testing/leaderboard_s6r1X.npy'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**200 trials for leaderboard MI test data for each subject 1-5**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pilotname='S1'\n",
    "savebase0='/home/moja/mne_data/MNE-beetlmileaderboard-data/'#'D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+pilotname+'/'+'testing/'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', \n",
    "           'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', \n",
    "           'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8',\n",
    "           'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', \n",
    "           'AFz', 'F1', 'F5', 'FT7', 'FC3', 'FCz', 'C1', 'C5', \n",
    "           'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', \n",
    "           'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2',\n",
    "           'FC4', 'FT8', 'F6', 'F2', 'AF4', 'AF8']\n",
    "#here we used the ones arround motor cortex\n",
    "good_indices=[7,8,11,12,13,14,19,22,23,24,28]+[39,40,43,44,45,51,52,53,54,57,58]\n",
    "good_indices[:] = [x - 1 for x in good_indices]\n",
    "\n",
    "for i in range(5,15):\n",
    "    with open (savebase+\"race\"+str(i+1)+\"_padsData.npy\", 'rb') as fp:\n",
    "        Xt = pickle.load(fp)\n",
    "    if i==5:\n",
    "        X0 = Xt\n",
    "    else:\n",
    "        X0 = np.concatenate((X0,Xt))\n",
    "    print('run',i+1)\n",
    "    print(X0.shape)   \n",
    "    \n",
    "X_test = X0[:,good_indices,:]\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "print(cuda)\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s1 = predicted_labels\n",
    "predicted_labels"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "run 6\n",
      "(20, 63, 2000)\n",
      "run 7\n",
      "(40, 63, 2000)\n",
      "run 8\n",
      "(60, 63, 2000)\n",
      "run 9\n",
      "(80, 63, 2000)\n",
      "run 10\n",
      "(100, 63, 2000)\n",
      "run 11\n",
      "(120, 63, 2000)\n",
      "run 12\n",
      "(140, 63, 2000)\n",
      "run 13\n",
      "(160, 63, 2000)\n",
      "run 14\n",
      "(180, 63, 2000)\n",
      "run 15\n",
      "(200, 63, 2000)\n",
      "overall test size\n",
      "(200, 22, 2000)\n",
      "True\n",
      "2000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\cnn_model_MI_S1.pth'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5eb6b3c929e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cnn_model_MI_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpilotname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/braindecode/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/braindecode/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/braindecode/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\cnn_model_MI_S1.pth'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pilotname='S2'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+pilotname+'\\\\'+'testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', \n",
    "           'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', \n",
    "           'O2', 'P4', 'P8', 'TP10', 'CP6', 'CP2', 'C4', 'T8',\n",
    "           'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', \n",
    "           'AFz', 'F1', 'F5', 'FT7', 'FC3', 'FCz', 'C1', 'C5', \n",
    "           'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', \n",
    "           'PO8', 'P6', 'P2', 'CPz', 'CP4', 'TP8', 'C6', 'C2',\n",
    "           'FC4', 'FT8', 'F6', 'F2', 'AF4', 'AF8']\n",
    "#here we used the ones arround motor cortex\n",
    "good_indices=[7,8,11,12,13,14,19,22,23,24,28]+[39,40,43,44,45,51,52,53,54,57,58]\n",
    "good_indices[:] = [x - 1 for x in good_indices]\n",
    "\n",
    "for i in range(5,15):\n",
    "    with open (savebase+\"race\"+str(i+1)+\"_padsData.npy\", 'rb') as fp:\n",
    "        Xt = pickle.load(fp)\n",
    "    if i==5:\n",
    "        X0 = Xt\n",
    "    else:\n",
    "        X0 = np.concatenate((X0,Xt))\n",
    "    print('run',i+1)\n",
    "    print(X0.shape)   \n",
    "    \n",
    "X_test = X0[:,good_indices,:]\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s2 = predicted_labels\n",
    "predicted_labels"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "run 6\n",
      "(20, 63, 2000)\n",
      "run 7\n",
      "(40, 63, 2000)\n",
      "run 8\n",
      "(60, 63, 2000)\n",
      "run 9\n",
      "(80, 63, 2000)\n",
      "run 10\n",
      "(100, 63, 2000)\n",
      "run 11\n",
      "(120, 63, 2000)\n",
      "run 12\n",
      "(140, 63, 2000)\n",
      "run 13\n",
      "(160, 63, 2000)\n",
      "run 14\n",
      "(180, 63, 2000)\n",
      "run 15\n",
      "(200, 63, 2000)\n",
      "overall test size\n",
      "(200, 22, 2000)\n",
      "2000\n",
      "(200,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2,\n",
       "       0, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 1, 0, 2, 0, 2,\n",
       "       1, 2, 2, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 2, 0, 1, 2, 1, 2, 1, 0, 0, 0, 1, 1, 2, 1, 1, 1, 0, 1, 2,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1,\n",
       "       0, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 0, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 2, 1, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 1, 0, 2, 0, 1, 2,\n",
       "       0, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pilotname='3'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s3 = predicted_labels\n",
    "predicted_labels"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 2,\n",
       "       2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2,\n",
       "       1, 2, 2, 2, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       1, 2, 1, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2,\n",
       "       0, 0, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 0, 1, 2,\n",
       "       1, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 1, 2, 1, 2, 2, 2, 1,\n",
       "       1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 0, 2, 1, 0,\n",
       "       1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 1, 0, 2, 0, 0, 2,\n",
       "       1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pilotname='4'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s4 = predicted_labels\n",
    "predicted_labels"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1,\n",
       "       0, 2, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2,\n",
       "       0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2,\n",
       "       2, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 2, 0, 1, 2, 2, 1, 0, 0, 1, 0,\n",
       "       2, 1, 2, 1, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 0,\n",
       "       2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0, 1,\n",
       "       0, 2, 0, 0, 2, 0, 2, 1, 2, 2, 1, 0, 2, 1, 2, 1, 0, 2, 0, 0, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 1,\n",
       "       2, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pilotname='5'\n",
    "savebase0='D:\\\\leaderboardData\\\\leaderboardMI\\\\'\n",
    "savebase = savebase0+'S'+pilotname+'\\\\testing\\\\'\n",
    "\n",
    "# read crop data\n",
    "ch_names =['Fp1', 'Fp2', 'F3', \n",
    "            'Fz', 'F4', 'FC5', 'FC1', 'FC2','FC6', 'C5', 'C3',\n",
    "           'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1',\n",
    "           'CPz', 'CP2', 'CP4', 'CP6', 'P7', 'P5', 'P3', 'P1', 'Pz', \n",
    "           'P2', 'P4', 'P6', 'P8']\n",
    "\n",
    "\n",
    "with open (savebase+\"testing_s\"+pilotname+\"X.npy\", 'rb') as fp:\n",
    "        X_test = pickle.load(fp)\n",
    "\n",
    "print('overall test size')\n",
    "print(X_test.shape)\n",
    "test_set = TestObject(X_test)\n",
    "\n",
    "set_random_seeds(seed=42, cuda=cuda)\n",
    "input_time_length = X_test.shape[2]\n",
    "print(input_time_length)\n",
    "in_chans=X_test.shape[1]\n",
    "labelsize=3\n",
    "model = util.shallow_net.EEGShallowClassifier(in_chans, labelsize, input_time_length, return_feature=False)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "checkpoint = torch.load('D:\\\\motor_imagery\\\\MImodelinLeaderboard\\\\'+'cnn_model_MI_'+pilotname+'.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "average_acc=[]\n",
    "average_loss=[]\n",
    "setname='testset'\n",
    "dataset=test_set\n",
    "\n",
    "i_trials_in_batch = get_balanced_batches(len(dataset.X), rng, shuffle=False,\n",
    "                                    batch_size=30)\n",
    "outputs=None\n",
    "for i_trials in i_trials_in_batch:\n",
    "    # Have to add empty fourth dimension to X\n",
    "#             print(i_trials)\n",
    "    batch_X = dataset.X[i_trials][:,:,:,None]\n",
    "#     batch_y = dataset.y[i_trials]\n",
    "    net_in = np_to_var(batch_X)\n",
    "    if cuda:\n",
    "        net_in = net_in.cuda()\n",
    "    toutputs = model(net_in)\n",
    "    if outputs is None:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=temp.detach().numpy()\n",
    "    else:\n",
    "        temp=toutputs.cpu()\n",
    "        outputs=np.concatenate((outputs,temp.detach().numpy()))\n",
    "predicted_labels = np.argmax((outputs), axis=1)\n",
    "print(predicted_labels.shape)\n",
    "MI_s5 = predicted_labels\n",
    "predicted_labels"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "overall test size\n",
      "(200, 32, 800)\n",
      "800\n",
      "(200,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 1,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 0, 1, 2, 0,\n",
       "       1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 1, 2,\n",
       "       2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 1,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**These will be the predicitons to save in a txt file. Format for text saving will be released in next update of this tutorial together with the release of leaderboard**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sleep_label.shape)\n",
    "print(MI_s1.shape)\n",
    "print(MI_s2.shape)\n",
    "print(MI_s3.shape)\n",
    "print(MI_s4.shape)\n",
    "print(MI_s5.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25748,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n",
      "(200,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sleep_label[:20])\n",
    "#label from 0 - 5\n",
    "np.savetxt(\"util/pred_sleep_label.txt\",sleep_label,delimiter=',',fmt=\"%d\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 0 0 2 2 1 1 2 2 2 0 0 1 1 5 0 2 2 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MI_label = MI_s1\n",
    "MI_label = np.concatenate((MI_label,MI_s2))\n",
    "MI_label = np.concatenate((MI_label,MI_s3))\n",
    "MI_label = np.concatenate((MI_label,MI_s4))\n",
    "MI_label = np.concatenate((MI_label,MI_s5))\n",
    "print(MI_label.shape)\n",
    "MI_label = MI_label.astype(int)\n",
    "MI_label[:100]\n",
    "#lable 0,1,2\n",
    "np.savetxt(\"util/pred_MI_label.txt\",MI_label,delimiter=',',fmt=\"%d\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**When you upload the txt label file to CodaLab, please rename the txt file as 'answer.txt' and zip it before uploading. The score is computed according to classification accuracies with weights of inverse frequency of a label.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('braindecode': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "interpreter": {
   "hash": "cffeb8d1e6e10cde4dc9144c81aedd5e77c0d4515a6ded66c4d5c6404fdc8e97"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}